\section{Les CNNs}

\fancyhead[R]{\textit{\nouppercase{\leftmark}}}

\subsection{Le modèle du CNN}

Bien qu'étant un modèle efficace, le perceptron reste cependant coûteux en calcul : il faut réaliser les opérations matricielles sur tous les neurones de chaque couches.
Cela peut sembler exagéré, surtout dans le cas de la classification d'images. 
En effet, chercher à reconnaître des motifs sur l'image complète s'avère inutile, quand on considère qu'un motif sera localisé sur l'image, et ne sera pas dépendant des points éloignés de l'image.

C'est de cette réflexion que sont apparus les CNNs (Convolutionnal Neural Networks), qui sont entrainés à chercher des motifs sur une partie restreinte de l'image.
Le principe est le même que celui des perceptrons, sauf qu'au lieu d'appliquer un réseau entièrement connectés sur toutes les couches, on va réaliser une convolution par un "filtre" sur l'image afin de permettre la localisation de motifs.
Une couche d'un CNN est typiquement constituée de 3 éléments : 

1) Une couche de convolution

2) Une couche d'activation 

3) Une couche de pooling


La couche de convolution prend en entrée une "image" de dimension (H, L, N), H la hauteur de l'image, L sa largeur et N le nombre de channels (pour une image RGB, on a N = 3). 
Elle va ensuite lui appliquer M filtres de dimension (h', l', N) :

\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{img/CNN_filtre.png}
 \caption{Principe des filtres de convolution}
\end{figure}

Pour une image I de dimension (H, L, N) et un filtre F de dimension (h', l', N), on obtient une image J de dimension (H-h', L-l'), la convolution est réalisée de la manière suivante :

\begin{equation}
    J(x, y) = I \star H (x, y) = \sum_{i=0}^{h' - 1} \sum_{j=0}^{l'- 1} \sum_{n=0}^{N - 1} I(x+i, y+j, n) \times H(i, j, n)
\end{equation}

On obtient alors une sortie de dimension (H-h', L-l', M).

Intuitivement, cette partie sert à chercher la ressemblance entre le filtre et l'image : 
On devrait avoir J(x,y) < 0 si la partie de l'image I en (x,y) est très différente du filtre appliqué, et J(x,y) > 0 sinon, avec un "score" plus ou moins élevé selon la ressemblance.


On applique ensuite la couche d'activation : on utilise une fonction non-linéaire comme dans le cas du perceptron. 
Communément, la fonction utilisée pour les couches de convolution intermédiaires est la fonction reLU :

\begin{equation}
    reLU (x) = x
\end{equation} si x > 0
\begin{equation}
    reLU (x) = 0 
\end{equation} sinon


\newpage 

Cette partie sert à ramener le résultat dans les réels positifs pour éviter une divergence au niveau des calculs, et pour augmenter l'écart relatif entre un bon score et un mauvais score : un score de 0 et en score de -1 obtenu lors de la convolution sont alors considéré comme tout aussi mauvais.

Enfin, on applique une couche de pooling, qui sert à réduire le nombre de données obtenues en sortie des 2 couches précédentes.
Le pooling cherche à "résumer" les scores d'une partie de l'image, en donnant un score qui dépend des pixels de cette partie.
Il existe plusieurs méthode de pooling, comme par exemple le pooling par moyenne, ou le pooling par maximum, qui est plus utilisé en pratique :
pour une image J, on choisi un paramètre S (S < L, H), et on otient la sortie K telle que :

\begin{equation}
    K(x, y) = max_{i,j \in [0, S-1] ^2 } { J(x \times S + i , y \times S + j ) }
\end{equation}


On peut ainsi enchainer les couches de convolution jusqu'à une couche finale, qui sera ensuite reliée à un réseau complètement connecté (qui n'est rien d'autre qu'un simple perceptron), pour pouvoir exploiter les résultats obtenus jusque là.
Les poids à optimiser sont alors les poids des matrices "filtres", et les poids de la couche entièrement connectée.
Dans le principe, un CNN est comme un perceptron (à part pour la couche de pooling, on pourrait construire un CNN avec un perceptron), à l'exception que certains poids sont liés lors de l'apprentissage. 

\subsection{Application pratique}

Afin de mieux comprendre le principe du CNN, nous avons réalisé un exemple simple mais clair : 
On cherche à reconnaître le motif d'une croix. 
Pour cela, on prend les filtres $f_1$ (diagonale gauche), $f_2$ (diagonale droite) et $f_3$ (croix centrale).
Alors en applicant la convolution, l'activation reLU et un stride à S = 2, on obtient le résultat suivant:

\begin{figure}[h]
    \center
    \includegraphics[width=0.5\textwidth]{img/cnn_exemple/cross/image_croix.png}
    \caption{image à détecter}
\end{figure}


\begin{figure}[!htb]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/filtre_1.png}
        \caption{filtre 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/filtre_2.png}
        \caption{filtre 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/filtre_3.png}
        \caption{filtre 3}
    \endminipage
\end{figure}

\newpage

\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/convolution_filtre_1.png}
        \caption{convolution filtre 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/convolution_filtre_2.png}
        \caption{convolution filtre 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/convolution_filtre_3.png}
        \caption{convolution filtre 3}
    \endminipage
\end{figure}

On remarque que les filtres en question réalisent bien l'action voulue : pour la première convolution, les positions des 
diagonales gauches sont mises en valeur, pour la seconde convolution, les diagonales droites sont mises en valeurs, 
et pour la troisième convolution, la croix centrale est mise en valeur.

\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/activation_relu_1.png}
        \caption{activation relu 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/activation_relu_2.png}
        \caption{activation relu 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/activation_relu_3.png}
        \caption{activation relu 3}
    \endminipage
\end{figure}

Après l'activation, on remarque peut de changement quand aux positions des motifs recherchés : 
ces positions sont toujours bien présentes, tandis dans que le reste de l'image où les motifs ne se trouvent pas, 
les valeurs sont "mises à niveau" pour bien insister sur le fait qu'elles n'apporteront pas d'informations pertinentes 
lors du traitement par perceptron.

\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/stride_1_max.png}
        \caption{stride 1 (max)}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/stride_2_max.png}
        \caption{stride 2 (max)}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/cross/stride_3_max.png}
        \caption{stride 3 (max)}
    \endminipage
\end{figure}

On peut ainsi réduire les dimensions de l'image, tout en conservant une postion globales des caractéristiques intéressantes.

On aperçoit alors l'apparition d'endroit à score élevé par rapport au reste.
On passe ensuite ces résultats dans un "réseau complètement connecté" (fully connected network) 
afin de pouvoir exploiter le contraste que ce réseau convolutionnel a mis en valeur.
Si on applique le même traitement à une autre figure (ici un carré), on remarque que le résultat est beacoup moins contrasté : 

\newpage

\begin{figure}[h]
    \center
    \includegraphics[width=0.5\textwidth]{img/cnn_exemple/square/image_carre.png}
    \caption{image à détecter}
\end{figure}


\begin{figure}[!htb]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/filtre_1.png}
        \caption{filtre 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/filtre_2.png}
        \caption{filtre 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/filtre_3.png}
        \caption{filtre 3}
    \endminipage
\end{figure}


\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/convolution_filtre_1.png}
        \caption{convolution filtre 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/convolution_filtre_2.png}
        \caption{convolution filtre 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/convolution_filtre_3.png}
        \caption{convolution filtre 3}
    \endminipage
\end{figure}

\newpage

\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/activation_relu_1.png}
        \caption{activation relu 1}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/activation_relu_2.png}
        \caption{activation relu 2}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/activation_relu_3.png}
        \caption{activation relu 3}
    \endminipage
\end{figure}


\begin{figure}[h]
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/stride_1_max.png}
        \caption{stride 1 (max)}
    \endminipage\hfill
    \minipage{0.32\textwidth}
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/stride_2_max.png}
        \caption{stride 2 (max)}
    \endminipage\hfill
    \minipage{0.32\textwidth}%
        \includegraphics[width=\textwidth]{img/cnn_exemple/square/stride_3_max.png}
        \caption{stride 3 (max)}
    \endminipage
\end{figure}

On remarque que le résultat final est beaucoup plus flouté, et n'apporte pas d'informations pertinentes pour le réseau de 
neurones arrivant derrière.

Dans le cas présenté ci-dessus, nous avons choisi nous-même les paramètres des filtres appliqués pour la convolution,
en se basant sur l'intuition.
En pratique, ces "filtres" sont appris comme des paramètres standards d'un réseau de neurones.

\subsection{Résultats}

Nous avons comparé les performances du CNN en comparaison avec un réseau de neurones complètement connecté sur la base de 
données MNIST.

Les entraînements on été réalisé sur 60000 éléments, par minibatches de 32.

Les réseaux considérés sont les suivants : 
\begin{itemize}
    \item Un perceptron de petite dimension (une couche cachée de taille 512)
    \item Un perceptron de grande dimension (deux couches cachées, de taille 4096 et 64)
    \item Un CNN (32 filtres de tailles 3$\times$3, 64 filtres de tailles 3$\times$3, un pooling max de taille 2$\times$ 2, une couche cachée de taille 128)
\end{itemize}

Le perceptron de grande dimension a été choisi de façon à avoir un nombre équivalent de paramètres avec le CNN.

\newpage

\begin{figure}[h]
    \center 
    \includegraphics{img/fc_vs_cnn.png}
    \caption{Comparaisons des performances pour des perceptrons et pour un CNN en fonction du nombres d'epochs. 
    CNN en vert, perceptron de petite dimension en bleu, perceptron de grande dimension en orange}
\end{figure}

On voit qu'au bout d'un passage complet sur les données (par minibatches de 32), le CNN obtient de meilleurs résultats que les 
perceptrons. De plus, on remarque que le perceptron de grande dimensions converge plus lentement que le réseau de petite dimension.
Le CNN sert alors à obtenir une convergence plus rapide (comme un perceptron de petite taille),
et obtient de meilleurs résultats à termes car il n'est pas limité par son nombre de paramètre (comme un perceptron de grande dimension).

La taille de filtres a une influence sur l'entraînement du CNN. En effet, les filtres ont pour bur de trouver des "motifs" dans l'image 
et de le mettre en valeur par rapport au reste de l'image. Plus le motif est petit, plus il sera facile d'entraîner le filtre, mais 
le motif alors trouvé ne sera pas forcement pertinent pour la classification. Inversement, plus le filtre est de grande dimension, plus 
il pourra rechercher des motifs complexes, mais la convergence sera alors plus compliquée et pas aussi stable.

\newpage

\begin{figure}[h]
    \center 
    \includegraphics{img/comparaison_filtres.png}
    \caption{Comparaisons des performances pour des perceptrons et pour un CNN en fonction du nombres d'epochs}
\end{figure}

En observant les résultats, on remarque que les filtres de 5$\times$5 ont un bon rapport performance/vitesse de convergence.