\BOOKMARK [1][-]{section*.3}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1}{Le Perceptron}{}% 2
\BOOKMARK [2][-]{subsection.1.1}{Mod\350le du perceptron}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.2}{Apprentissage}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.3}{La fonction d'erreur}{section.1}% 5
\BOOKMARK [3][-]{subsubsection.1.3.1}{Comportement pour une erreur quadratique}{subsection.1.3}% 6
\BOOKMARK [3][-]{subsubsection.1.3.2}{Origine de cet \351chec}{subsection.1.3}% 7
\BOOKMARK [3][-]{subsubsection.1.3.3}{Une solution \340 ce probl\350me d'apprentissage}{subsection.1.3}% 8
\BOOKMARK [3][-]{subsubsection.1.3.4}{Une explication intuitive}{subsection.1.3}% 9
\BOOKMARK [3][-]{subsubsection.1.3.5}{Estimateur de l'entropie crois\351e}{subsection.1.3}% 10
\BOOKMARK [2][-]{subsection.1.4}{La fonction XOR}{section.1}% 11
\BOOKMARK [2][-]{subsection.1.5}{MNIST}{section.1}% 12
\BOOKMARK [2][-]{subsection.1.6}{Un la\357us sur les diff\351rents optimiseurs Paul ?}{section.1}% 13
\BOOKMARK [1][-]{section.2}{Les CNN}{}% 14
\BOOKMARK [2][-]{subsection.2.1}{Le mod\350le du CNN}{section.2}% 15
\BOOKMARK [2][-]{subsection.2.2}{Application pratique}{section.2}% 16
\BOOKMARK [2][-]{subsection.2.3}{R\351sultats}{section.2}% 17
\BOOKMARK [2][-]{subsection.2.4}{Utilisation de TensorFlow}{section.2}% 18
\BOOKMARK [1][-]{section.3}{Le Q-Learning}{}% 19
\BOOKMARK [2][-]{subsection.3.1}{Qu'est-ce que le Q-Learning ?}{section.3}% 20
\BOOKMARK [2][-]{subsection.3.2}{Calculer la fonction Q}{section.3}% 21
\BOOKMARK [2][-]{subsection.3.3}{Jeu des b\342tonnets}{section.3}% 22
\BOOKMARK [2][-]{subsection.3.4}{Le labyrinthe}{section.3}% 23
\BOOKMARK [1][-]{section.4}{Le Deep Q-Learning}{}% 24
\BOOKMARK [2][-]{subsection.4.1}{Principe du Deep Q-Learning}{section.4}% 25
\BOOKMARK [2][-]{subsection.4.2}{Jeu des b\342tonnets}{section.4}% 26
\BOOKMARK [2][-]{subsection.4.3}{Changements effectu\351s pour le passage \340 Pong}{section.4}% 27
\BOOKMARK [3][-]{subsubsection.4.3.1}{Deux Deep Q-Networks}{subsection.4.3}% 28
\BOOKMARK [3][-]{subsubsection.4.3.2}{Optimiseur RMSProp}{subsection.4.3}% 29
\BOOKMARK [3][-]{subsubsection.4.3.3}{Changement de configuration de r\351seau}{subsection.4.3}% 30
\BOOKMARK [3][-]{subsubsection.4.3.4}{Apprentissage}{subsection.4.3}% 31
\BOOKMARK [3][-]{subsubsection.4.3.5}{Probl\350mes de m\351moire}{subsection.4.3}% 32
\BOOKMARK [2][-]{subsection.4.4}{Pong}{section.4}% 33
\BOOKMARK [3][-]{subsubsection.4.4.1}{Apprentissage sur 3000 parties}{subsection.4.4}% 34
\BOOKMARK [3][-]{subsubsection.4.4.2}{Apprentissage sur 7000 parties}{subsection.4.4}% 35
\BOOKMARK [2][-]{subsection.4.5}{CartPole}{section.4}% 36
\BOOKMARK [3][-]{subsubsection.4.5.1}{Principe du jeu}{subsection.4.5}% 37
\BOOKMARK [3][-]{subsubsection.4.5.2}{Apprentissage de CartPole}{subsection.4.5}% 38
\BOOKMARK [3][-]{subsubsection.4.5.3}{Apprentissage avec un seul r\351seau}{subsection.4.5}% 39
\BOOKMARK [2][-]{subsection.4.6}{Flappy Bird}{section.4}% 40
\BOOKMARK [3][-]{subsubsection.4.6.1}{Principe}{subsection.4.6}% 41
\BOOKMARK [3][-]{subsubsection.4.6.2}{Apprentissage}{subsection.4.6}% 42
\BOOKMARK [1][-]{section*.41}{Conclusion}{}% 43
